# W3C Solid Community Group: Authentication Panel

* Date: 2021-10-11T14:00:00Z
* Call: https://meet.jit.si/solid-authentication
* Chat: https://gitter.im/solid/authentication-panel
* Repository: https://github.com/solid/authentication-panel


## Present
* [Sarven Capadisli](https://csarven.ca/#i)
* Aaron Coburn
* Michiel de Jong
* elf Pavlik
* Pete Edwards
* Nicolas AS
* Barath

---

## Announcements

### Meeting Recordings and Transcripts
* No audio or video recording, or automated transcripts without consent. Meetings are transcribed and made public. If consent is withheld by anyone, recording/retention must not occur.
* Use panel chat and repository. Queue in call to talk.


### Participation and Code of Conduct
* [Join the W3C Solid Community Group](https://www.w3.org/community/solid/join), [W3C Account Request](http://www.w3.org/accounts/request), [W3C Community Contributor License Agreement](https://www.w3.org/community/about/agreements/cla/)
* [Solid Code of Conduct](https://github.com/solid/process/blob/master/code-of-conduct.md), [Positive Work Environment at W3C: Code of Ethics and Professional Conduct](https://github.com/solid/process/blob/master/code-of-conduct.md)
* If this is your first time, welcome! please introduce yourself.


### Scribes
* Sarven


### Introductions
* Pete Edwards (Inrupt): working on conformance test harness that allows it to link to spec and produce reports. looking at this meeting to see how we do OIDC tests and whether things need to change in the harness or fits.
* Michiel: used to work on Solid OS. helped build oidc server. part of the WebID provider tests. simple: login and to access a pod. uses a headless browser called [puppeteer](https://pptr.dev/).

---

## Agenda

* SC: Please provide feedback to [W3C Solid Community Group Meeting Guidelines](https://github.com/solid/specification/pull/319/).
* Test Suite discussion [#22](https://github.com/solid/solid-oidc/issues/22)
    * OpenID Provider/IdP (OP)
    * Resource Server/Pod Server (RS)
    * Relying Party/Solid App (RP)
* Open PRs
    * [Remove solid:PublicOidcClient](https://github.com/solid/solid-oidc/pull/48)
    * [Add webid scope requirement](https://github.com/solid/solid-oidc/pull/49)
    * [Add support for link header discovery](https://github.com/solid/solid-oidc/pull/50)
* WWW-Authenticate Header [#25](https://github.com/solid/solid-oidc/issues/25)
* Documentation of supported spec features [#195](https://github.com/solid/authentication-panel/issues/195)
* Interest in meeting with AuthZ panel this Wednesday.

---

## Topics

### W3C Solid Community Group Meeting Guidelines
URL: https://github.com/solid/specification/pull/319/

* SC: Please provide feedback. That's all.
* AC: Generally +1 to anything that's not cumbersome.

### Test Suite discussion
URL: https://github.com/solid/solid-oidc/issues/22

* AC: Some context: right now we have a couple of different tests. The primary (my impression): it is about testing the Solid protocol, which largely consists of operations on the server. They all rely on the fact that the server retrieved the access token. It is a bit of a hole for Solid OIDC spec. This conversation is about figuring out how to fix that, and determining the approach and/or structure for these tests. One of the challenges: the regular test harness and test suite are mostly not browser based. In context of Solid OIDC, three things that needs to be tested: 
  1. IdP 
  2. resource server - it is getting a lot of tests 
  3. relying party (app) - we dont have any/much testing that. 
  ... One of the challenges with these kinds of tests: in OIDC, for the typical flow used by clients, it is left to implementations to define what happens at the login stage. All of that is implementation specific, so out-of-scope for OpenID Connect.

* MdJ: You're right when you have WAC and CRUD tests. For the CRUD tests, you can also run them on localhost with auth turned off. You're testing part of the storage server — the RS. But for the RP, we have nothing. I guess that'd be hard to test. Need to check app / need to interact complex way. We don't know much about the login flow. We do know about the discovery OIDC endpoint, and the token you want to receive, and we have the WebID provider test. Those are testing IDPs. There are three versions of it. It can run 3 tests.
  1. NSS
  2. PHPSoliverserer -- using curl
  3. NextCloud - turned out to be more difficult. The login screen is protected so it doesn't seem to work for curl. So we use the headless browser. We refer to CSS elements. Find the box? It expects the redirect to follow, etc.
  ... These tests do exist for only those servers. They run in node / puppeteer. they work. Testing discovery to see all things are there. Test the login flow with the redirects and whatever flow is returned from the browser.

* AC: (Authorization Code flow)

* MdJ:

* eP: I'd like to be part of the common test suite. It will be important to distinguish between implementation-specific behaviors and those common features required by Solid-OIDC. The implementation-specific interactions can include biometrics  / client certificates. I think we separate those from the Solid-OIDC specific features in a test suite.

* AC: Rhetorical Question: when M was describing implementation-specific code. As more implementations come along, I would foresee a lot more implementation-specific code. Is there a structure we can develop that will allow us to avoid so much implementation-specific code? For example: within a single test suite.

* PE: To complete the picture on the CTS, it has the ability to refresh tokens on the normal auth flow and client_credentials. It just uses them for the sake of testing other things? For example, there is specific code around CSS, so we have examples around specific servers, but not a coherent set of tests.

* AC: I suggest an answer to my question from before. One way to do this: to test the OP (not the other two areas) across implementations. What i'm suggesting is: it could be an entirely browser-based app — basically, a static JS app — leading the OIDC flow for a given browser. As you proceed in that flow, it can check a number of things. Have that code generate a report, e.g., I have JS (terrible, but, it sits online and I use it frequently...) What is the structure of the id token and access token? https://people.apache.org/~acoburn/solid/ is bare bones. If you do login and give the URL of the issuer... From there, if you were to take that approach, we can simply then check the values to see if it conforms to various requirements or features of the spec.

* MdJ: That looks useful. It could test any IDP no matter the interaction, as long as the human does the clicking. If we want to be aware / test the areas to instruct the user, e.g., type in the wrong password to see what happens, consent to certain scopes but not to other scopes. Maybe the instructions are to login and `yes` to everything, but then there are 5 different scenarios. Need to login but not something else. There are advs to automated tests, ci requires a human being. Let's have both especially it can be open ended for any IdP. Will link to it.

* eP: The tests should be run against live OpenID provider. ?? If we ask them to deploy ??? could be modified in some way. Can we find some common way that can allow implementers to have limited burden, to provide the test suite a way to get implementation-specific tests? Perhaps to give a cookie... If we can think of a way, less burden on implementers ... so move that to imp side if they want to get that from the test suite

* PE: We need the ability to set up artifacts, either that has to be through API or agree in advance with server implementers on server states. Also need the ability to tear down. Either have an API ??? we have different tests and don't want to clash with tests.

* AC: We should be careful with scoping: we're want to test Solid-OIDC, rather than all of OpenID Connect. While Solid-OIDC builds on OpenID Connect, we don't need to test every failure mode that OpenID Connect defines. That'd be a lot to bite off for test suite implementers. If Solid-OIDC tests the so called "happy path", that'd be sufficient initially, but it'd be good to test other permutations... but in terms of providing incorrect credentials, etc., I don't know if we necessarily need to test that.

* eP: For this imp-specific test auth OPs: somehow the cookie could be set... Can we maybe have a common way to obtain that cookie? Trying to look, what'd be the place out of scope... and ask imp to provide something that the test suite doesn't have to? will do some research.

* AC: This gets to Pete's question. What is the mechanism by which CLI-based test suites interact with an RS? One of the challenges with OpenID Connect is that there are many permutations (e.g., client credentials, refresh tokens). Because we are building on top of OpenID connect, we are only mandating authorization code flow. Some of the identity systems do these other mechanisms, providing facilities to refresh... Test suite can make use of this, but not sure if it needs to be standardised.

* MdJ: We use the cookie trick for WAC tests, but it turned out to be confusing for implementers. It worked there to have one call to get the cookie. But at the same time, the login screens are part of what you are testing. Normally you have a login and consent screen, so it is only partial.  I like Aaron's remark. Are we allowed to login at this IdP? That'd be great; then we can see what the format is, if expiry is valid, or slashes on the IdP, or some other incompatibilities. So for that, manual tests are perfect. For automated tests, that'd be something more for implementers want.. setting cookies ??? you'd probably want to use a headless browser to go through screens, which is what you (seem?) to be doing, so it'd be hard to generalise. We'll almost necessarily have the automated test never be universal because it is open ended on how UIs work. So manual test would be useful to add what we have now. There is more use in putting energy with what Aaron started with manual tests. We could extend ??? that'd be not one test suite that can handle all IdPs.

* eP: We could start for all conf classes. What we want to test: I don't think for Solid-OIDC we want to test the login OP. Imp are encouraged to test, but I don't think that's part of the common test suite. What we could start is what we want to include, e.g., format of tokens. I don't think the login screen will appear there.

* AC: This is good conversation. Would like to move forward with a specific plan. We have a need for automated tests for CI, but thats more than conformance testing. It seems manual, but browser based. I'm happy to take as an action — not this week — to basically take that code as starting point, clean it up, so that's actually testing what Solid-OIDC is testing. Just a starting point, to see how we model these tests. There is an open question if this is part of the Solid-OIDC repo or different, but public somewhere.

PROPOSAL: Take the code in https://people.apache.org/~acoburn/solid/ as a starting point for OP conformance testing 

* eP: +1 as separate repository
* AC: +1
* NAS: +1
* MdJ: +1
* PE: +1

RESOLUTION: general agreement, "Take the code in https://people.apache.org/~acoburn/solid/ as a starting point for OP conformance testing". use separate repo — solid-oidc-tests

ACTION: SC to create solid-oidc-tests

* PE: One thing we've been doing is going through tests to see what's identified in specs. We identified what we want to test, automated manually. When we are reporting, we can link back to that spec.

* AC: That's critical, really being clear about what we're testing, and for all of those things we have tests. Another proposal is to take as an action to list out / identify, all things in Solid-OIDC that need to be tested.

ACTION: AC (not this week but will do) to write down all of the items that should be tested for Solid-OIDC, and ensure that each item has an identifying URI.

* PE: We can enhance that, e.g., when we have a manifest file, to know if it is manual or automatic.

* AC: Makes sense. Any metadata to identify what we are testing (as well as how we are testing: manual or automated). We can write down all requirements, and refer back to the spec but open to other suggestions.

* SC: Make sure identifiers are in the spec.

* AC: That'd be part of the review.

* eP: If you want to do a draft PR, I can help.

* AC: Thanks. That will involve iteration.

  ... should we try to wrap up this discussion and continue next week, or press on? We also have open PRs that we need to go through. Noting eP's +1 to prioritize testing due to participation

* MdJ: Who needs to be tested for that paragraph? Is this req on the idp or RS or RP? In general, it is not part of the OIDC spec, but it does play a role in solid app and pod. In that auth dialog which pops up when you log in, even when proven identity but not get access. You also need to somehow test whether user consented to using that app. Some will be reqs on apps. Was curious whether the manual tests: for the idp or .. extend those to ... authorize this app. maybe even test apps.

* AC: The code is entirely focused on OP; whether we should extend, I might want to think about that some more. More inclined to keep them modular, because the code ends up simpler, but not opposed to testing both. 

* eP: Some of the things are related to authz. That brings us back to issue: reconcile the work in authn/z panel, and how they're combining. We can pick it up in the authz-panel, to coordinate.

* AC: It is potentially going to get more complicated ongoing conversation, e.g., UMA-based flow. That's some variability that we need to consider for any testing scenario. That's why I wanted to keep the tests separate, how an implementation pulls these things together.

* AC: We have an OP, RS, RP. We talk about OP/IdP. In terms of RP/app, as MdJ points out, let's start with what's easier, namely the RS: if we are able to design something, and this is for the test suite, effectively to test the RS, there is a hook — get me an access token, and we don't define what that means, but if you're able to get the AT or id token from the IdP, that could be the path forward for how we handle the RS testing...

* eP: That complements the RP, client, and OP. We could safely test the client to OP interaction. We can test the RS interaction, and for the RP/client, that'd be impacted by authz. We should take that co-dependency with the authz into account.

* AC: There's been some work in the past — basically create a mock IdP — that might be helpful in these RS-OP interactions. It generates a token with limited access for that WebID; you can then begin testing that RS. One thing that may make things easier: build out or reuse existing infrastructure that has mock IdP, that generates valid access tokens for a well known WebID. If the RS under test gives limited permissions to that well known WebID, you can begin to test RS. There may be prior art for this, but we would need to verify conformance with the current state of Solid-OIDC.

* eP: It'd be great if you start, and we can pick up the conversation, as it is not currently written down what would be tested on the RS side; e.g., we could test www-authenticate, but that doesn't involve authz. Maybe we can all out another meeting with test suite panel?

* AC: We can continue this conv in async and also in future meeting. Once we create this test suite repo, for the solid-oidc spec, I'll put a note on gitter channels and invite people. I do know that Pavlik has something small to bring up regarding the authz panel.

* eP: Coordinate over Gitter chat. I can write down more about the overlap, impact on both panels regarding interaction with the RS. We can start conv this week and regularly pick up the parts that are related.

